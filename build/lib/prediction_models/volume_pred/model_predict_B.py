# src/prediction_models/volume_pred/model_predict_B.py

import json
from pathlib import Path

import joblib
import numpy as np
import pandas as pd


FEATURE_PATH = Path("data/intermediate/features/time_series_features.csv")
MODEL_DIR = Path("models/artifacts/volume_model_B")
OUTPUT_PATH = Path("data/output/volume_prediction_result_B.csv")


def load_features() -> pd.DataFrame:
    """åŠ è½½ç‰¹å¾æ•°æ®ï¼ˆæ–¹æ¡ˆ Bï¼šä¸ç”¨é¢„æµ‹ä»·æ ¼ï¼Œä»…ä½¿ç”¨å®Œæ•´ç‰¹å¾è¡¨ï¼‰"""
    if not FEATURE_PATH.exists():
        raise FileNotFoundError(f"ç‰¹å¾æ–‡ä»¶ä¸å­˜åœ¨ï¼š{FEATURE_PATH}")
    df = pd.read_csv(FEATURE_PATH)

    # ç¡®ä¿ ts ä¸º datetimeï¼Œä¾¿äºæ—¶é—´åˆ‡åˆ†
    if "ts" in df.columns:
        df["ts"] = pd.to_datetime(df["ts"], errors="coerce")

    return df


def load_metadata(horizon: int) -> dict:
    meta_path = MODEL_DIR / f"metadata_{horizon}d.json"
    if not meta_path.exists():
        raise FileNotFoundError(f"æœªæ‰¾åˆ°å…ƒæ•°æ®æ–‡ä»¶ï¼š{meta_path}")
    with open(meta_path, "r", encoding="utf-8") as f:
        return json.load(f)


def load_model(horizon: int):
    model_path = MODEL_DIR / f"model_{horizon}d.pkl"
    if not model_path.exists():
        raise FileNotFoundError(f"æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ï¼š{model_path}")
    return joblib.load(model_path)


def main():
    print("ğŸ“¥ è¯»å–ç‰¹å¾æ•°æ® ...")
    df = load_features()
    df = df.sort_values("ts").reset_index(drop=True)

    n_total = len(df)
    split_idx = int(n_total * 0.8)
    valid_df = df.iloc[split_idx:].copy()
    print(f"ğŸ“Œ ä½¿ç”¨å 20% æ•°æ®ä½œä¸ºéªŒè¯é›†è¿›è¡Œé¢„æµ‹ï¼švalid_rows={len(valid_df):,}")

    # æ ‡è¯†åˆ—ï¼ˆæ–¹ä¾¿åç»­å¯¹æ¥ä¸šåŠ¡æˆ–è¯„ä¼°ï¼‰
    id_cols_candidate = [
        "ts",
        "product_id",
        "variety",
        "classify_name",
        "shop_name",
        "spec",
        "grade",
        "color",
        "market_name",
        "place",
    ]
    id_cols = [c for c in id_cols_candidate if c in valid_df.columns]

    # ç»“æœè¡¨ï¼šå…ˆæ”¾ id åˆ—
    result = valid_df[id_cols].copy() if id_cols else valid_df[["ts"]].copy()

    # é¡ºä¾¿æŠŠçœŸå®å€¼åˆ—ä¹Ÿä¸€å¹¶å†™å‡ºï¼ˆæ–¹ä¾¿åç»­è¯„ä¼°ï¼‰
    for target_col in ["y_volume_1d", "y_volume_2d", "y_volume_3d"]:
        if target_col in valid_df.columns:
            # åŸå§‹ CSV ä¸­æ˜¯åŸå§‹æˆäº¤é‡ï¼Œä¸éœ€è¦ expm1ï¼Œå‰ªæ‰è´Ÿå€¼å³å¯
            result[target_col] = valid_df[target_col].clip(lower=0)

    # ä¾æ¬¡åŠ è½½ 1/2/3 å¤©çš„æ¨¡å‹åšé¢„æµ‹
    for horizon in [1, 2, 3]:
        target_col = f"y_volume_{horizon}d"
        meta = load_metadata(horizon)
        feature_cols = meta["features"]
        cat_cols = meta.get("categorical_features", []) or []

        # æ£€æŸ¥ç‰¹å¾åˆ—æ˜¯å¦é½å…¨
        missing_cols = [c for c in feature_cols if c not in valid_df.columns]
        if missing_cols:
            raise ValueError(f"h={horizon}d ç¼ºå°‘ç‰¹å¾åˆ—ï¼š{missing_cols}")

        # æŒ‰è®­ç»ƒæ—¶ä¸€è‡´çš„æ–¹å¼å¤„ç†ç±»åˆ«åˆ—
        for col in cat_cols:
            if col in valid_df.columns:
                valid_df[col] = valid_df[col].astype("category")

        model = load_model(horizon)
        X_valid = valid_df[feature_cols]

        print(f"â–¶ é¢„æµ‹ {horizon} æ—¥æˆäº¤é‡ï¼ˆæ–¹æ¡ˆ Bï¼Œä»…å†å²ä»·æ ¼ï¼‰ ...")
        # æ¨¡å‹è¾“å‡ºçš„æ˜¯ log1p(volume)ï¼Œè¿™é‡Œåå˜æ¢å›åŸå§‹æˆäº¤é‡
        y_pred_log = model.predict(X_valid)
        y_pred = np.expm1(y_pred_log)
        # é˜²æ­¢æº¢å‡º / inf / nan
        y_pred = np.where(np.isfinite(y_pred), y_pred, np.nan)
        # ä¸å…è®¸è´Ÿæˆäº¤é‡
        y_pred = np.maximum(y_pred, 0)

        pred_col = f"pred_volume_{horizon}d_B"
        result[pred_col] = y_pred

    OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)
    result.to_csv(OUTPUT_PATH, index=False, encoding="utf-8-sig")
    print(f"âœ… æ–¹æ¡ˆ B é¢„æµ‹ç»“æœå·²å†™å…¥ï¼š{OUTPUT_PATH}")
    print("   å­—æ®µç¤ºä¾‹ï¼šts, product_id, variety, ..., y_volume_1d/2d/3d, pred_volume_1d/2d/3d_B")


if __name__ == "__main__":
    main()
