# src/prediction_models/short_term_price_pred/model_train.py
"""
çŸ­æœŸä»·æ ¼é¢„æµ‹æ¨¡å‹è®­ç»ƒè„šæœ¬ï¼ˆæ—¶é—´åºåˆ—åˆ‡åˆ†ç‰ˆï¼‰
A æ­¥ï¼š1/2/3 å¤©ä»·æ ¼é¢„æµ‹æ¨¡å‹è®­ç»ƒ

æ›´æ–°å†…å®¹ï¼š
âœ” å–æ¶ˆéšæœºåˆ‡åˆ†ï¼ˆtrain_test_splitï¼‰
âœ” æ”¹ä¸ºçœŸæ­£çš„æ—¶é—´åºåˆ—åˆ‡åˆ†ï¼ˆå‰ 80% è®­ç»ƒï¼Œå 20% éªŒè¯ï¼‰
âœ” ç‰¹å¾ç¼–ç ä½¿ç”¨ category.codesï¼Œé¿å… dtype é”™è¯¯
âœ” ç”Ÿæˆä¸ä¿å­˜æ¨¡å‹ + å…ƒæ•°æ®

ä½¿ç”¨æ–¹å¼ï¼š
    python -m src.prediction_models.short_term_price_pred.model_train
"""

from __future__ import annotations

import json
from dataclasses import dataclass, asdict
from pathlib import Path
from typing import List, Tuple, Dict

import joblib
import numpy as np
import pandas as pd
from lightgbm import LGBMRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error

# -------------------------
# è·¯å¾„ä¸å¸¸é‡
# -------------------------

ROOT = Path(__file__).resolve().parents[3]
DATA_DIR = ROOT / "data"
FEATURE_DIR = DATA_DIR / "intermediate" / "features"
FEATURE_CSV = FEATURE_DIR / "time_series_features.csv"

MODEL_ROOT = ROOT / "models" / "artifacts" / "price_model_v1"
MODEL_ROOT.mkdir(parents=True, exist_ok=True)

TS_COL = "ts"
TRAIN_FRACTION = 0.8
RANDOM_STATE = 42


@dataclass
class ModelTrainReport:
    horizon: int
    target_col: str
    n_train: int
    n_valid: int
    train_date_range: str
    valid_date_range: str
    mae: float
    rmse: float
    mape: float
    feature_count: int
    categorical_features: List[str]
    model_params: Dict


# -------------------------
# æ•°æ®åŠ è½½
# -------------------------

def load_feature_data() -> pd.DataFrame:
    """è¯»å–ç‰¹å¾å·¥ç¨‹è¾“å‡ºæ–‡ä»¶"""
    if not FEATURE_CSV.exists():
        raise FileNotFoundError(f"ç‰¹å¾æ–‡ä»¶ä¸å­˜åœ¨ï¼š{FEATURE_CSV}")
    df = pd.read_csv(FEATURE_CSV)
    df[TS_COL] = pd.to_datetime(df[TS_COL])
    return df


# -------------------------
# æ—¶é—´åˆ‡åˆ†æ„å»ºè®­ç»ƒé›†/éªŒè¯é›†
# -------------------------

def build_train_valid_split(
    df: pd.DataFrame, target_col: str
) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series, List[str], List[str], pd.Index, pd.Index]:

    # åˆ é™¤æ²¡æœ‰ç›®æ ‡å€¼çš„è¡Œ
    df = df.dropna(subset=[target_col]).copy()

    # æŒ‰æ—¶é—´æ’åº
    df = df.sort_values(TS_COL).reset_index(drop=True)

    # è®¡ç®—æ—¶é—´åˆ‡åˆ†ç‚¹
    n_total = len(df)
    split_idx = int(n_total * TRAIN_FRACTION)

    df_train = df.iloc[:split_idx].copy()
    df_valid = df.iloc[split_idx:].copy()

    # ç›®æ ‡åˆ—
    target_cols = [c for c in df.columns if c.startswith("y_price_") or c.startswith("y_volume_")]
    drop_cols = set(target_cols + [TS_COL])

    feature_cols = [c for c in df.columns if c not in drop_cols]

    X_train = df_train[feature_cols].copy()
    y_train = df_train[target_col]

    X_valid = df_valid[feature_cols].copy()
    y_valid = df_valid[target_col]

    # æ‰¾ç±»åˆ«åˆ—ï¼ˆobjectï¼‰
    categorical_cols = [c for c in feature_cols if X_train[c].dtype == "object"]

    # ç±»åˆ«ç¼–ç ï¼ˆä¸æ³„æ¼æœªæ¥ï¼‰
    for col in categorical_cols:
        X_train[col] = X_train[col].astype("category").cat.codes.astype("int32")
        X_valid[col] = X_valid[col].astype("category").cat.codes.astype("int32")

    return (
        X_train,
        X_valid,
        y_train,
        y_valid,
        feature_cols,
        categorical_cols,
        df_train.index,
        df_valid.index,
    )


# -------------------------
# æ¨¡å‹è®­ç»ƒ
# -------------------------

def train_single_horizon_model(horizon: int) -> ModelTrainReport:
    target_col = f"y_price_{horizon}d"

    print("\n======================")
    print(f"â–¶ å¼€å§‹è®­ç»ƒ {horizon} æ—¥æ¨¡å‹ï¼ˆtarget={target_col}ï¼‰")
    print("======================")

    df = load_feature_data()

    (
        X_train,
        X_valid,
        y_train,
        y_valid,
        feature_cols,
        categorical_cols,
        train_idx,
        valid_idx,
    ) = build_train_valid_split(df, target_col)

    # LightGBM å‚æ•°
    model_params = {
        "objective": "regression",
        "n_estimators": 600,
        "learning_rate": 0.05,
        "num_leaves": 64,
        "subsample": 0.8,
        "colsample_bytree": 0.8,
        "reg_alpha": 0.1,
        "reg_lambda": 0.2,
        "random_state": RANDOM_STATE,
        "n_jobs": -1,
    }

    model = LGBMRegressor(**model_params)

    # è®­ç»ƒæ¨¡å‹
    model.fit(
        X_train,
        y_train,
        eval_set=[(X_valid, y_valid)],
        eval_metric="l1",
    )

    # éªŒè¯é›†é¢„æµ‹
    y_pred = model.predict(X_valid)

    mae = float(mean_absolute_error(y_valid, y_pred))
    rmse = float(np.sqrt(mean_squared_error(y_valid, y_pred)))
    mape = float(np.mean(np.abs((y_valid - y_pred) / (y_valid + 1e-6))))

    # æ—¥æœŸèŒƒå›´
    train_range = f"{df.loc[train_idx, TS_COL].min()} ~ {df.loc[train_idx, TS_COL].max()}"
    valid_range = f"{df.loc[valid_idx, TS_COL].min()} ~ {df.loc[valid_idx, TS_COL].max()}"

    print(f"ğŸ“Š {horizon} æ—¥éªŒè¯é›†ï¼šMAE={mae:.4f} RMSE={rmse:.4f} MAPE={mape:.2%}")

    # ä¿å­˜æ¨¡å‹
    model_path = MODEL_ROOT / f"model_{horizon}d.pkl"
    metadata_path = MODEL_ROOT / f"metadata_{horizon}d.json"

    joblib.dump(model, model_path)

    report = ModelTrainReport(
        horizon=horizon,
        target_col=target_col,
        n_train=len(X_train),
        n_valid=len(X_valid),
        train_date_range=train_range,
        valid_date_range=valid_range,
        mae=mae,
        rmse=rmse,
        mape=mape,
        feature_count=len(feature_cols),
        categorical_features=categorical_cols,
        model_params=model_params,
    )

    with open(metadata_path, "w", encoding="utf-8") as f:
        json.dump(asdict(report), f, ensure_ascii=False, indent=2)

    # åŒæ­¥ä¿å­˜é»˜è®¤æ¨¡å‹ï¼ˆ1 æ—¥ï¼‰
    if horizon == 1:
        joblib.dump(model, MODEL_ROOT / "model.pkl")
        with open(MODEL_ROOT / "metadata.json", "w", encoding="utf-8") as f:
            json.dump(asdict(report), f, ensure_ascii=False, indent=2)

    return report


# -------------------------
# å…¥å£
# -------------------------

def main():
    print("ğŸŒ¼ å¼€å§‹è®­ç»ƒçŸ­æœŸä»·æ ¼é¢„æµ‹æ¨¡å‹ï¼ˆæ—¶é—´åºåˆ—åˆ‡åˆ†ç‰ˆï¼‰...")
    reports: List[ModelTrainReport] = []

    for h in [1, 2, 3]:
        try:
            r = train_single_horizon_model(h)
            reports.append(r)
        except KeyError:
            print(f"âš ï¸ æ•°æ®ä¸­ç¼ºå°‘ y_price_{h}dï¼Œè·³è¿‡ã€‚")

    print("\n======================")
    print("âœ… æ‰€æœ‰æ¨¡å‹è®­ç»ƒå®Œæˆï¼ˆæ—¶é—´åˆ‡åˆ†ç‰ˆï¼‰")
    print("======================")

    for r in reports:
        print(
            f"- {r.horizon} æ—¥ï¼šMAE={r.mae:.4f} RMSE={r.rmse:.4f} MAPE={r.mape:.2%} "
            f"è®­ç»ƒæ ·æœ¬={r.n_train:,} éªŒè¯æ ·æœ¬={r.n_valid:,}"
        )


if __name__ == "__main__":
    main()
