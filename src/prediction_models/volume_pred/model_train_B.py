# src/prediction_models/volume_pred/model_train_B.py

import pandas as pd
import numpy as np
import lightgbm as lgb
from pathlib import Path
import json
import joblib

FEATURE_PATH = Path("data/intermediate/features/time_series_features.csv")
MODEL_DIR = Path("models/artifacts/volume_model_B/")
MODEL_DIR.mkdir(parents=True, exist_ok=True)


def load_features() -> pd.DataFrame:
    df = pd.read_csv(FEATURE_PATH)

    # æ–¹æ¡ˆ Bï¼šä¸ç”¨é¢„æµ‹ä»·æ ¼ â†’ ç›´æ¥ä¸¢æ‰ pred_price_* åˆ—ï¼ˆå³ä½¿æœ‰ä¹Ÿä¸ç”¨ï¼‰
    for col in ["pred_price_1d", "pred_price_2d", "pred_price_3d"]:
        if col in df.columns:
            df = df.drop(columns=[col])

    # ts è½¬ datetimeï¼Œåé¢æŒ‰æ—¶é—´åˆ‡åˆ†
    df["ts"] = pd.to_datetime(df["ts"], errors="coerce")

    return df


def train_single_model(horizon: int, df: pd.DataFrame):
    target = f"y_volume_{horizon}d"

    # -------- ç‰¹å¾é€‰æ‹©ï¼šå»æ‰æ ‡ç­¾ & ts --------
    drop_cols = [
        "ts",
        # æ‰€æœ‰ y æ ‡ç­¾
        "y_price_1d", "y_volume_1d",
        "y_price_2d", "y_volume_2d",
        "y_price_3d", "y_volume_3d",
        target,  # å½“å‰ horizon çš„ç›®æ ‡åˆ—
    ]

    feature_cols = [c for c in df.columns if c not in drop_cols]

    # log1p å¤„ç†ç›®æ ‡ï¼ˆæˆäº¤é‡é•¿å°¾ï¼‰
    df = df.copy()
    df[target] = np.log1p(df[target])

    # -------- åœ¨æ•´ä¸ª df ä¸ŠæŠŠç±»åˆ«åˆ—ç»Ÿä¸€è½¬æˆ category --------
    obj_cols = df[feature_cols].select_dtypes(include=["object"]).columns.tolist()
    for col in obj_cols:
        df[col] = df[col].astype("category")

    # -------- æŒ‰æ—¶é—´åˆ‡åˆ†ï¼ˆæ›´æ¥è¿‘çœŸå®åœºæ™¯ï¼‰ --------
    df = df.sort_values("ts")
    split_idx = int(len(df) * 0.8)
    train_df = df.iloc[:split_idx]
    valid_df = df.iloc[split_idx:]

    X_train, y_train = train_df[feature_cols], train_df[target]
    X_valid, y_valid = valid_df[feature_cols], valid_df[target]

    # -------- LightGBM æ¨¡å‹ --------
    model = lgb.LGBMRegressor(
        objective="regression",
        n_estimators=500,
        learning_rate=0.03,
        num_leaves=64,
        subsample=0.7,
        colsample_bytree=0.8,
    )

    model.fit(
        X_train, y_train,
        eval_set=[(X_valid, y_valid)],
        eval_metric="rmse",
        callbacks=[lgb.early_stopping(50)],
    )

    # -------- ä¿å­˜æ¨¡å‹ --------
    model_path = MODEL_DIR / f"model_{horizon}d.pkl"
    joblib.dump(model, model_path)

    # -------- ä¿å­˜å…ƒæ•°æ® --------
    meta = {
        "horizon": horizon,
        "features": feature_cols,
        "categorical_features": obj_cols,
        "train_rows": len(train_df),
        "valid_rows": len(valid_df),
    }
    with open(MODEL_DIR / f"metadata_{horizon}d.json", "w", encoding="utf-8") as f:
        json.dump(meta, f, ensure_ascii=False, indent=2)

    print(
        f"âœ… æ–¹æ¡ˆ Bï¼šç¬¬ {horizon} å¤©æˆäº¤é‡æ¨¡å‹è®­ç»ƒå®Œæˆ â†’ {model_path} "
        f"(train={len(train_df):,}, valid={len(valid_df):,})"
    )


def main():
    df = load_features()
    print(f"ğŸ“Š æ–¹æ¡ˆ B å¯ç”¨è®­ç»ƒæ ·æœ¬æ•°ï¼š{len(df):,}")

    for h in [1, 2, 3]:
        train_single_model(h, df)


if __name__ == "__main__":
    main()
