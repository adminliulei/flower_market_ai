# src/prediction_models/common/feature_engineering.py
"""
Feature Engineering for Flower Market AI

åŸºäºå‰ç½®æ­¥éª¤ï¼š
- C1: preliminary_cleaning
- D : missing_value_filling
- C2: outlier_detection
- E : price_index (flower_price_index)

ç›®æ ‡ï¼š
1. ä» C2 è¾“å‡ºçš„ market_price_cleaned.csv æ„é€ è®­ç»ƒæ ·æœ¬ç‰¹å¾ï¼›
2. å°† E æ­¥ç”Ÿæˆçš„èŠ±ä»·æŒ‡æ•°ï¼ˆå…¨å¸‚åœº / å¤§ç±» / å“ç§ï¼‰åˆå¹¶ä¸ºç‰¹å¾ï¼›
3. æ„é€ æ—¶é—´ç‰¹å¾ã€æ»åç‰¹å¾ã€æ»šåŠ¨çª—å£ç‰¹å¾ã€å¼‚å¸¸ä¸æ³¢åŠ¨ç‰¹å¾ï¼›
4. ç”Ÿæˆæœªæ¥ 1/2/3 å¤©ä»·æ ¼ & æˆäº¤é‡é¢„æµ‹ç›®æ ‡ (y)ï¼›
5. è¾“å‡ºåˆ°ï¼š
   - data/intermediate/features/time_series_features.csv
   - data/intermediate/features/category_features.csv
"""

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import List

import numpy as np
import pandas as pd

# -------------------------
# è·¯å¾„ & å¸¸é‡
# -------------------------

# âœ… ä¿®æ­£ï¼šé¡¹ç›®æ ¹ç›®å½•åº”è¯¥æ˜¯ parents[3]ï¼ˆ.../flower_market_aiï¼‰
ROOT = Path(__file__).resolve().parents[3]

DATA_DIR = ROOT / "data"
PROCESSED_DIR = DATA_DIR / "processed"
INTERMEDIATE_DIR = DATA_DIR / "intermediate"
FEATURE_DIR = INTERMEDIATE_DIR / "features"
INDICES_DIR = INTERMEDIATE_DIR / "indices"

CLEANED_CSV = PROCESSED_DIR / "market_price_cleaned.csv"  # C2 è¾“å‡º
PRICE_INDEX_CSV = INDICES_DIR / "flower_price_index.csv"  # E è¾“å‡º

TIME_SERIES_FEATURES_CSV = FEATURE_DIR / "time_series_features.csv"
CATEGORY_FEATURES_CSV = FEATURE_DIR / "category_features.csv"

TS_COL = "ts"
PRICE_COL = "retail_price"
VOLUME_COL = "volume"

GROUP_KEYS: List[str] = [
    "product_id",
    "variety",
    "spec",
    "grade",
    "shop_name",
    "classify_name",
    "color",
]


@dataclass
class FeatureSummary:
    """ç‰¹å¾å·¥ç¨‹ç»“æœç®€è¦è¯´æ˜"""

    n_rows: int
    n_features: int
    date_range: str
    n_products: int
    targets: List[str]


# -------------------------
# å·¥å…·å‡½æ•°
# -------------------------

def _ensure_types(df: pd.DataFrame) -> pd.DataFrame:
    """ç»Ÿä¸€å…³é”®å­—æ®µç±»å‹"""
    df = df.copy()
    df[TS_COL] = pd.to_datetime(df[TS_COL])
    df[PRICE_COL] = pd.to_numeric(df[PRICE_COL], errors="coerce")
    df[VOLUME_COL] = pd.to_numeric(df[VOLUME_COL], errors="coerce")
    return df


def _add_time_features(df: pd.DataFrame) -> pd.DataFrame:
    """å¢åŠ æ—¶é—´è¡ç”Ÿç‰¹å¾"""
    df = df.copy()
    dt = df[TS_COL].dt

    df["day_of_week"] = dt.weekday  # 0-6, å‘¨ä¸€=0
    df["is_weekend"] = df["day_of_week"].isin([5, 6]).astype(int)
    df["week_of_year"] = dt.isocalendar().week.astype(int)
    df["month"] = dt.month
    df["day_of_month"] = dt.day

    if "holiday_flag" in df.columns:
        df["holiday_flag"] = df["holiday_flag"].fillna(0).astype(int)
    else:
        df["holiday_flag"] = 0

    return df


def _add_lag_features(
    df: pd.DataFrame,
    lags_price: List[int] = [1, 2, 3, 7],
    lags_volume: List[int] = [1, 2, 3, 7],
) -> pd.DataFrame:
    """æŒ‰å•†å“ç»´åº¦å¢åŠ ä»·æ ¼ & æˆäº¤é‡æ»åç‰¹å¾"""
    df = df.copy()
    df.sort_values(GROUP_KEYS + [TS_COL], inplace=True)

    g = df.groupby(GROUP_KEYS, dropna=False)

    for lag in lags_price:
        df[f"price_lag_{lag}"] = g[PRICE_COL].shift(lag)

    for lag in lags_volume:
        df[f"volume_lag_{lag}"] = g[VOLUME_COL].shift(lag)

    # å·®åˆ†ç‰¹å¾
    df["price_diff_1"] = df[PRICE_COL] - df["price_lag_1"]
    df["price_diff_7"] = df[PRICE_COL] - df["price_lag_7"]
    df["volume_diff_1"] = df[VOLUME_COL] - df["volume_lag_1"]

    return df


def _add_rolling_features(
    df: pd.DataFrame,
    price_windows: List[int] = [3, 7, 14, 30],
    volume_windows: List[int] = [7, 14],
) -> pd.DataFrame:
    """å¢åŠ ä»·æ ¼ / æˆäº¤é‡æ»šåŠ¨çª—å£ç‰¹å¾"""
    df = df.copy()
    df.sort_values(GROUP_KEYS + [TS_COL], inplace=True)

    g = df.groupby(GROUP_KEYS, dropna=False)

    for win in price_windows:
        df[f"price_ma_{win}"] = g[PRICE_COL].transform(
            lambda s, w=win: s.rolling(window=w, min_periods=max(2, w // 2)).mean()
        )
        df[f"price_std_{win}"] = g[PRICE_COL].transform(
            lambda s, w=win: s.rolling(window=w, min_periods=max(2, w // 2)).std(ddof=0)
        )
        df[f"price_cv_{win}"] = df[f"price_std_{win}"] / df[f"price_ma_{win}"]

    for win in volume_windows:
        df[f"volume_ma_{win}"] = g[VOLUME_COL].transform(
            lambda s, w=win: s.rolling(window=w, min_periods=max(2, w // 2)).mean()
        )
        df[f"volume_std_{win}"] = g[VOLUME_COL].transform(
            lambda s, w=win: s.rolling(window=w, min_periods=max(2, w // 2)).std(ddof=0)
        )

    if "price_ma_7" in df.columns and "price_ma_30" in df.columns:
        df["price_ma_ratio_7_30"] = df["price_ma_7"] / df["price_ma_30"]

    if "volume_ma_7" in df.columns and "volume_ma_14" in df.columns:
        df["volume_ma_ratio_7_14"] = df["volume_ma_7"] / df["volume_ma_14"]

    return df


def _load_price_index():
    """è¯»å–èŠ±ä»·æŒ‡æ•°é•¿è¡¨ï¼Œå¹¶æ‹†åˆ†ä¸ºå…¨å¸‚åœº / å¤§ç±» / å“ç§ä¸‰éƒ¨åˆ†"""
    idx = pd.read_csv(PRICE_INDEX_CSV)
    idx["ts"] = pd.to_datetime(idx["ts"])

    # å…¨å¸‚åœº
    idx_all = (
        idx[idx["scope_type"] == "all"]
        .rename(
            columns={
                "price_index": "idx_all_price",
                "total_volume": "idx_all_volume",
                "index_ma7": "idx_all_ma7",
                "index_ma30": "idx_all_ma30",
                "index_return": "idx_all_return",
            }
        )
        .loc[
            :,
            [
                "ts",
                "idx_all_price",
                "idx_all_volume",
                "idx_all_ma7",
                "idx_all_ma30",
                "idx_all_return",
            ],
        ]
    )

    # å¤§ç±»
    idx_cls = (
        idx[idx["scope_type"] == "classify"]
        .rename(
            columns={
                "scope_value": "classify_name",
                "price_index": "idx_cls_price",
                "total_volume": "idx_cls_volume",
                "index_ma7": "idx_cls_ma7",
                "index_ma30": "idx_cls_ma30",
                "index_return": "idx_cls_return",
            }
        )
        .loc[
            :,
            [
                "ts",
                "classify_name",
                "idx_cls_price",
                "idx_cls_volume",
                "idx_cls_ma7",
                "idx_cls_ma30",
                "idx_cls_return",
            ],
        ]
    )

    # å“ç§
    idx_var = (
        idx[idx["scope_type"] == "variety"]
        .rename(
            columns={
                "scope_value": "variety",
                "price_index": "idx_var_price",
                "total_volume": "idx_var_volume",
                "index_ma7": "idx_var_ma7",
                "index_ma30": "idx_var_ma30",
                "index_return": "idx_var_return",
            }
        )
        .loc[
            :,
            [
                "ts",
                "variety",
                "idx_var_price",
                "idx_var_volume",
                "idx_var_ma7",
                "idx_var_ma30",
                "idx_var_return",
            ],
        ]
    )

    return idx_all, idx_cls, idx_var


def _merge_price_index(df: pd.DataFrame) -> pd.DataFrame:
    """å°†èŠ±ä»·æŒ‡æ•°ï¼ˆå…¨å¸‚åœº + å¤§ç±» + å“ç§ï¼‰åˆå¹¶åˆ°æ˜ç»†æ•°æ®ä¸Š"""
    df = df.copy()
    idx_all, idx_cls, idx_var = _load_price_index()

    df = df.merge(idx_all, on="ts", how="left")

    if "classify_name" in df.columns:
        df = df.merge(idx_cls, on=["ts", "classify_name"], how="left")

    if "variety" in df.columns:
        df = df.merge(idx_var, on=["ts", "variety"], how="left")

    return df


def _add_targets(df: pd.DataFrame, horizons: List[int] = [1, 2, 3]) -> pd.DataFrame:
    """ç”Ÿæˆæœªæ¥ 1/2/3 å¤©ä»·æ ¼ & æˆäº¤é‡é¢„æµ‹ç›®æ ‡"""
    df = df.copy()
    df.sort_values(GROUP_KEYS + [TS_COL], inplace=True)

    g = df.groupby(GROUP_KEYS, dropna=False)

    for h in horizons:
        df[f"y_price_{h}d"] = g[PRICE_COL].shift(-h)
        df[f"y_volume_{h}d"] = g[VOLUME_COL].shift(-h)

    return df


def _build_category_mapping(df: pd.DataFrame) -> pd.DataFrame:
    """æ„é€ ç±»åˆ«å­—æ®µçš„ ID æ˜ å°„è¡¨"""
    cat_cols = ["variety", "classify_name", "grade", "color", "shop_name"]
    records = []

    for col in cat_cols:
        if col not in df.columns:
            continue
        uniq_vals = df[col].dropna().astype(str).unique()
        for idx, val in enumerate(sorted(uniq_vals)):
            records.append(
                {
                    "category_type": col,
                    "category_value": val,
                    "category_id": idx,
                }
            )

    mapping_df = pd.DataFrame(records)
    return mapping_df


# -------------------------
# ä¸»æµç¨‹ï¼šæ„å»ºç‰¹å¾
# -------------------------

def build_features(
    cleaned_csv: Path = CLEANED_CSV,
    price_index_csv: Path = PRICE_INDEX_CSV,
) -> FeatureSummary:
    """æ ¸å¿ƒå…¥å£ï¼šæ„é€ å…¨éƒ¨ç‰¹å¾å¹¶è¾“å‡º CSV"""
    if not cleaned_csv.exists():
        raise FileNotFoundError(f"Cleaned csv not found: {cleaned_csv}")
    if not price_index_csv.exists():
        raise FileNotFoundError(f"Price index csv not found: {price_index_csv}")

    print(f"ğŸ“¥ è¯»å–æ¸…æ´—åæ•°æ®ï¼š{cleaned_csv}")
    df = pd.read_csv(cleaned_csv)
    df = _ensure_types(df)

    print("ğŸ§© å¢åŠ æ—¶é—´ç‰¹å¾ ...")
    df = _add_time_features(df)

    print("ğŸ§© åˆå¹¶èŠ±ä»·æŒ‡æ•°ç‰¹å¾ï¼ˆE æ­¥ï¼‰ ...")
    df = _merge_price_index(df)

    print("ğŸ§© æ„é€ ä»·æ ¼/é”€é‡æ»åç‰¹å¾ ...")
    df = _add_lag_features(df)

    print("ğŸ§© æ„é€ æ»šåŠ¨çª—å£ç‰¹å¾ ...")
    df = _add_rolling_features(df)

    print("ğŸ¯ ç”Ÿæˆæœªæ¥ 1/2/3 å¤©é¢„æµ‹ç›®æ ‡ (y) ...")
    df = _add_targets(df)

    target_cols = [c for c in df.columns if c.startswith("y_price_") or c.startswith("y_volume_")]
    df = df.dropna(subset=target_cols)

    print("ğŸ§© ç”Ÿæˆç±»åˆ«æ˜ å°„è¡¨ ...")
    category_df = _build_category_mapping(df)

    FEATURE_DIR.mkdir(parents=True, exist_ok=True)
    print(f"ğŸ’¾ å†™å‡ºç‰¹å¾æ•°æ®ï¼š{TIME_SERIES_FEATURES_CSV}")
    df.to_csv(TIME_SERIES_FEATURES_CSV, index=False)

    print(f"ğŸ’¾ å†™å‡ºç±»åˆ«æ˜ å°„è¡¨ï¼š{CATEGORY_FEATURES_CSV}")
    category_df.to_csv(CATEGORY_FEATURES_CSV, index=False)

    date_range = f"{df[TS_COL].min()} ~ {df[TS_COL].max()}"
    summary = FeatureSummary(
        n_rows=len(df),
        n_features=df.shape[1],
        date_range=date_range,
        n_products=df["product_id"].nunique() if "product_id" in df.columns else 0,
        targets=target_cols,
    )
    return summary


# -------------------------
# è„šæœ¬å…¥å£
# -------------------------

def main():
    print("ğŸŒ¼ å¼€å§‹æ‰§è¡Œç‰¹å¾å·¥ç¨‹ï¼ˆFeature Engineeringï¼‰ ...")
    summary = build_features()

    print("\nğŸ“Œ ç‰¹å¾å·¥ç¨‹æ‘˜è¦ï¼š")
    print(f"- æ ·æœ¬è¡Œæ•°ï¼š{summary.n_rows:,}")
    print(f"- ç‰¹å¾æ€»æ•°ï¼š{summary.n_features}")
    print(f"- è¦†ç›–å•†å“æ•°ï¼š{summary.n_products}")
    print(f"- æ—¥æœŸèŒƒå›´ï¼š{summary.date_range}")
    print(f"- ç›®æ ‡åˆ—ï¼š{', '.join(summary.targets)}")
    print("\nâœ… ç‰¹å¾å·¥ç¨‹å®Œæˆï¼Œå¯ç”¨äº A/B æ¨¡å‹è®­ç»ƒã€‚")


if __name__ == "__main__":
    main()
